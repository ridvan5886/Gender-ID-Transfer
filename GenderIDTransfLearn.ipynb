{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFi9dyzcCXvP"
      },
      "source": [
        "### `list_attr_celeba` Dataset\n",
        "A popular component of computer vision and deep learning revolves around identifying faces for various applications from logging into your phone with your face or searching through surveillance images for a particular suspect. This dataset is great for training and testing models for face detection, particularly for recognising facial attributes such as finding people with brown hair, are smiling, or wearing glasses. Images cover large pose variations, background clutter, diverse people, supported by a large quantity of images and rich annotations. This data was originally collected by researchers at MMLAB, The Chinese University of Hong Kong (specific reference in Acknowledgment section).\n",
        "\n",
        "\n",
        "\n",
        "- 202,599 number of face images of various celebrities\n",
        "- 10,177 unique identities, but names of identities are not given\n",
        "- 40 binary attribute annotations per image\n",
        "\n",
        "You can obtain the dataset from https://www.kaggle.com/jessicali9530/celeba-dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AeCYM4mxI06v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIS-Yp9iCXvV",
        "outputId": "5fe39bc5-2e0b-4012-dec3-9812634c2af7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img  # Import load_img from TensorFlow\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YAa4rQ9CXvX",
        "outputId": "60c344bb-d926-4b3d-8338-324c4dbbca3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Facial_keypoints.ipynb', 'GenderIDex.JPG', 'Transfer_learning.ipynb', 'img_align_celeba.zip', 'Week2-Class1-St.zip', 'weights.best.hdf5', '.DS_Store', 'Week2-Class1-St', 'test', 'weights-improvement-17-0.66.hdf5', 'weights-improvement-76-0.74.hdf5', 'weights-improvement-71-0.73.hdf5', 'input', 'small_c_d', 'weights-improvement-43-0.69.hdf5', 'weights-improvement-109-0.76.hdf5', 'celeb_small', 'weights-improvement-51-0.69.hdf5', 'weights-improvement-28-0.67.hdf5', 'weights-improvement-140-0.76.hdf5', 'Celeb_sets', 'P1_Facial_Keypoints', 'Gender_ID_VGG16.py', 'weights-improvement-57-0.71.hdf5', 'get-start-image-classification.ipynb', 'weights-improvement-79-0.75.hdf5', 'cats_dogs', 'list_attr_celeba.csv', 'test1.zip', 'train', 'weights-improvement-01-0.66.hdf5', 'model.h5', 'vgg16_1.h5', 'Gender_ID_VGG16_v02.py', '.ipynb_checkpoints', 'weights-improvement-41-0.69.hdf5', 'Gender_ID_Inception.py', 'diabetes.csv', 'Week2-Class1-Inst', 'weights-improvement-29-0.68.hdf5', 'weights-improvement-60-0.72.hdf5', 'weights-improvement-144-0.77.hdf5', 'train.zip', 'weights-improvement-56-0.70.hdf5', 'img_align_celeba']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
              "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
              "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair',\n",
              "       'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee',\n",
              "       'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male',\n",
              "       'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
              "       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
              "       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair',\n",
              "       'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n",
              "       'Wearing_Necklace', 'Wearing_Necktie', 'Young'], dtype=object)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mypath='/Users/gceran/Google Drive/Courses/MagniMind/Mentorship Program/DL-MentorProgram/DL_Mentor_Week2/Class 1'\n",
        "print(os.listdir(mypath))\n",
        "\n",
        "df=pd.read_csv(mypath+'/list_attr_celeba.csv')\n",
        "\n",
        "df.head()\n",
        "df.columns.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "400a293df3c8499059d9175f3915187074efd971",
        "id": "07dP8X4kCXvZ"
      },
      "source": [
        "#### See sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WihQlnmCXvZ"
      },
      "outputs": [],
      "source": [
        "# Function to load and preprocess images\n",
        "def load_preprocess_image(filename):\n",
        "    img = load_img(os.path.join(img_directory, filename), target_size=(178, 218))\n",
        "    img = preprocess_input(np.array(img))\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample image\n",
        "sample_image_id = df['image_id'].iloc[0]  # Take the first image from the dataset as a sample\n",
        "sample_image = load_preprocess_image(sample_image_id)\n",
        "\n",
        "# Denormalize the image to display it correctly\n",
        "denormalized_image = (sample_image + 1) / 2  # Convert from [-1, 1] range to [0, 1] range\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(denormalized_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mW4WQXtH0AfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpCs5AaRCXvZ"
      },
      "source": [
        "### 4. Build Model\n",
        "\n",
        "- First, copy VGG16 without the dense layers, use the weights from `imagenet`. Set the input shape to `(178,218,3)`.\n",
        "- Freeze the layers except the last two layers and print to see if the layers are trainable or not.\n",
        "- Build your sequential model (you are free to use a functioanl API as a further exercise). Include all the frozen VGG layers to your model. Add a Dense layer with 128 inouts and `relu` activation. Add a batch nomalizer, then a dense layer as the output layer.\n",
        "- Create an early stopping criteria monitorin the loss value for the validation set. Stop the search if the loss value deosnt change for two consecutive times.\n",
        "- Compile the model.\n",
        "- Save the best model automatically based on the performance of the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSJPYossCXvZ"
      },
      "outputs": [],
      "source": [
        "# Build the Model\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(178, 218, 3))\n",
        "\n",
        "# Freeze layers except the last two\n",
        "for layer in vgg_base.layers[:-2]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create the sequential model and add the layers\n",
        "model = Sequential()\n",
        "model.add(vgg_base)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(40, activation='sigmoid'))  # Assuming there are 40 binary attributes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping and ModelCheckpoint callbacks and save the best model automatically\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "E9jS424SwyBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-dKodFTCXva"
      },
      "source": [
        "## 5. Data Preparation\n",
        "\n",
        "- Create a validation set with 20% of the data. Check the number of data points per class from both the train and validation sets.\n",
        "- Set your batch size to 20.\n",
        "- Create the data generator and set the `preprocessing_function` to `preprocess_input` of VGG16.\n",
        "- Create train and validation data generators (batches will be picked up from the dataframe). Set target size to (178,218) (you can try something else, but you need to do the corresponding change in the model).\n",
        "- Set your validation  and epoch step size (`validation_steps` and `steps_per_epoch`)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "# Create a validation set with 20% of the data\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the number of data points per class in both train and validation sets\n",
        "train_counts = train_df.sum(axis=0).iloc[1:]\n",
        "val_counts = val_df.sum(axis=0).iloc[1:]\n",
        "print(\"Train Data Class Distribution:\")\n",
        "print(train_counts)\n",
        "print(\"\\nValidation Data Class Distribution:\")\n",
        "print(val_counts)\n",
        "\n"
      ],
      "metadata": {
        "id": "gjMKHMCpw11G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch size\n",
        "batch_size = 20\n",
        "\n",
        "# Create data generators\n",
        "train_data_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        ")\n",
        "\n",
        "val_data_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "seF5mOydw2AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqH6hWhBCXva"
      },
      "source": [
        "## 6. Train the Model\n",
        "\n",
        "- Fit the model\n",
        "- save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGTioNzWCXva"
      },
      "outputs": [],
      "source": [
        "# Train and validation data generators\n",
        "train_generator = train_data_gen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=img_directory,\n",
        "    x_col='image_id',\n",
        "    y_col=train_df.columns[1:],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    target_size=(178, 218),\n",
        "    class_mode='raw'\n",
        ")\n",
        "\n",
        "val_generator = val_data_gen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=img_directory,\n",
        "    x_col='image_id',\n",
        "    y_col=val_df.columns[1:],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    target_size=(178, 218),\n",
        "    class_mode='raw'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the validation and epoch step size\n",
        "validation_steps = len(val_generator)\n",
        "steps_per_epoch = len(train_generator)"
      ],
      "metadata": {
        "id": "3swF42HHxDvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=20,  # You can adjust the number of epochs as needed\n",
        "    callbacks=[early_stopping, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "yi7r_rKLxDyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model\n",
        "model.save('final_model.h5')\n"
      ],
      "metadata": {
        "id": "SS2gbUBSxD5j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}